{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Convolutional-neural-networks.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoXe6rTChARC"
      },
      "source": [
        "# Chapter 6: Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "h4-hU75GhARE",
        "outputId": "5689f876-83f9-4754-8902-783e48f47702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "W1 assignment \n",
        "\n",
        "First of all, we start importing the Keras module and checking its version\n",
        "''' \n",
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTDZG7JehARG"
      },
      "source": [
        "Basic elements of a convolutional neuronal network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep1Y3Es5hARH",
        "outputId": "69791634-b8f0-4571-8436-01683e90eb11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "W1 assignment\n",
        "\n",
        "Now it's time to define our model.\n",
        "\n",
        "After importing all the submodules we will need (sequential, Dense and sgd)\n",
        "we define our model.\n",
        "\n",
        "It consists of:\n",
        "  * an input layer of 10 neurons. Each neuron receives 784 inputs corresponding\n",
        "  to every sample and has a 'sigmoid' activation function at their output.\n",
        "  * an output layer of 10 neurons. Since it is a classification problem using\n",
        "  'softmax' as its activation function is convenient.\n",
        "\n",
        "Finally, we print the summary of our model to have a better understanding of its\n",
        "architecture.\n",
        "\n",
        "The number of parameters of our model is composed of the following:\n",
        "  * Input layer: 780 features * 10 neurons + 1 bias * 10 = 7850\n",
        "  * Output layer: 10 outputs from input layer * 10 neurons + 1 bias * 10 = 110\n",
        "\n",
        "This results in 7850 + 110 = 7960 parameters.\n",
        "'''\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
            "=================================================================\n",
            "Total params: 832\n",
            "Trainable params: 832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPZJjd9bhARI"
      },
      "source": [
        "Basic CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8dGCwxophARI",
        "outputId": "291f5fd9-d1fb-4af0-c927-5ae8bc782a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "W1 assignment\n",
        "\n",
        "Now it's time to define our model.\n",
        "\n",
        "After importing all the submodules we will need (sequential, Dense and sgd)\n",
        "we define our model.\n",
        "\n",
        "It consists of:\n",
        "  * an input layer of 10 neurons. Each neuron receives 784 inputs corresponding\n",
        "  to every sample and has a 'sigmoid' activation function at their output.\n",
        "  * an output layer of 10 neurons. Since it is a classification problem using\n",
        "  'softmax' as its activation function is convenient.\n",
        "\n",
        "Finally, we print the summary of our model to have a better understanding of its\n",
        "architecture.\n",
        "\n",
        "The number of parameters of our model is composed of the following:\n",
        "  * Input layer: 780 features * 10 neurons + 1 bias * 10 = 7850\n",
        "  * Output layer: 10 outputs from input layer * 10 neurons + 1 bias * 10 = 110\n",
        "\n",
        "This results in 7850 + 110 = 7960 parameters.\n",
        "'''\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "=================================================================\n",
            "Total params: 52,096\n",
            "Trainable params: 52,096\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx1MPK-LhARJ"
      },
      "source": [
        "\n",
        "'''\n",
        "W1 assignment\n",
        "\n",
        "Now it's time to define our model.\n",
        "\n",
        "After importing all the submodules we will need (sequential, Dense and sgd)\n",
        "we define our model.\n",
        "\n",
        "It consists of:\n",
        "  * an input layer of 10 neurons. Each neuron receives 784 inputs corresponding\n",
        "  to every sample and has a 'sigmoid' activation function at their output.\n",
        "  * an output layer of 10 neurons. Since it is a classification problem using\n",
        "  'softmax' as its activation function is convenient.\n",
        "\n",
        "Finally, we print the summary of our model to have a better understanding of its\n",
        "architecture.\n",
        "\n",
        "The number of parameters of our model is composed of the following:\n",
        "  * Input layer: 780 features * 10 neurons + 1 bias * 10 = 7850\n",
        "  * Output layer: 10 outputs from input layer * 10 neurons + 1 bias * 10 = 110\n",
        "\n",
        "This results in 7850 + 110 = 7960 parameters.\n",
        "'''\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "z1NUoKMqhARK",
        "outputId": "bb794feb-2e71-483d-de8a-2abd9be66bc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 62,346\n",
            "Trainable params: 62,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vj_jknMhARM",
        "outputId": "63f6ed66-9e1a-4537-fa5d-24774ac2ec59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "W1 assignment\n",
        "\n",
        "Now it's time to define our model.\n",
        "\n",
        "After importing all the submodules we will need (sequential, Dense and sgd)\n",
        "we define our model.\n",
        "\n",
        "It consists of:\n",
        "  * an input layer of 10 neurons. Each neuron receives 784 inputs corresponding\n",
        "  to every sample and has a 'sigmoid' activation function at their output.\n",
        "  * an output layer of 10 neurons. Since it is a classification problem using\n",
        "  'softmax' as its activation function is convenient.\n",
        "\n",
        "Finally, we print the summary of our model to have a better understanding of its\n",
        "architecture.\n",
        "\n",
        "The number of parameters of our model is composed of the following:\n",
        "  * Input layer: 780 features * 10 neurons + 1 bias * 10 = 7850\n",
        "  * Output layer: 10 outputs from input layer * 10 neurons + 1 bias * 10 = 110\n",
        "\n",
        "This results in 7850 + 110 = 7960 parameters.\n",
        "'''\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print (train_images.shape)\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsjPFmRmhARO",
        "outputId": "8e599ac2-8251-4bcb-9943-fd8291579fd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "W1 assignment\n",
        "\n",
        "Now that we've defined our model it's time to compile and fit it to our dataset.\n",
        "We have also to define our hyperparameters such as:\n",
        "  * batch size\n",
        "  * number of epochs\n",
        "  * loss function\n",
        "  * optimizing function\n",
        "\n",
        "In our case we compile our model with the following hyper-parameters:\n",
        "  * loss function: categorical_crossentropy. This is the function used in Keras \n",
        "  for multiclassification problems.\n",
        "  * optimizer: sgd. Stochastic Gradient Descent is the most common and \n",
        "  famous optimizer.\n",
        "  * metrics: accuracy. We want to know how well our model performs in terms of \n",
        "  accuracy when classifying our samples, in contrast with regression problems,\n",
        "  where we want to know the amount of error obtained.\n",
        "\n",
        "After compiling, we proceed to fit our model by indicating both the features and\n",
        "labels sets and also the number of epochs (10) and the batch size (50).\n",
        "\n",
        "Once fitted, we evaluate our output model using the features and labels sets.\n",
        "\n",
        "Finally, we obtain a test accuracy of 0.88 (88%), which is pretty good.\n",
        "'''\n",
        "batch_size = 100\n",
        "epochs = 5\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1\n",
        "          )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "600/600 [==============================] - 60s 98ms/step - loss: 0.9532 - accuracy: 0.7588\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 59s 98ms/step - loss: 0.2687 - accuracy: 0.9213\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 59s 98ms/step - loss: 0.1913 - accuracy: 0.9445\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 59s 98ms/step - loss: 0.1509 - accuracy: 0.9563\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 59s 98ms/step - loss: 0.1271 - accuracy: 0.9633\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd44115f1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GivNBOk4hARQ"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7sI59QO3hARR",
        "outputId": "da68287d-95ff-418f-a124-219d52a2f870"
      },
      "source": [
        "'''\n",
        "W1 assignment\n",
        "\n",
        "Now that we've defined our model it's time to compile and fit it to our dataset.\n",
        "We have also to define our hyperparameters such as:\n",
        "  * batch size\n",
        "  * number of epochs\n",
        "  * loss function\n",
        "  * optimizing function\n",
        "\n",
        "In our case we compile our model with the following hyper-parameters:\n",
        "  * loss function: categorical_crossentropy. This is the function used in Keras \n",
        "  for multiclassification problems.\n",
        "  * optimizer: sgd. Stochastic Gradient Descent is the most common and \n",
        "  famous optimizer.\n",
        "  * metrics: accuracy. We want to know how well our model performs in terms of \n",
        "  accuracy when classifying our samples, in contrast with regression problems,\n",
        "  where we want to know the amount of error obtained.\n",
        "\n",
        "After compiling, we proceed to fit our model by indicating both the features and\n",
        "labels sets and also the number of epochs (10) and the batch size (50).\n",
        "\n",
        "Once fitted, we evaluate our output model using the features and labels sets.\n",
        "\n",
        "Finally, we obtain a test accuracy of 0.88 (88%), which is pretty good.\n",
        "'''\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 266us/step\n",
            "Test loss: 0.11137229395359755\n",
            "Test accuracy: 0.9673\n"
          ]
        }
      ]
    }
  ]
}